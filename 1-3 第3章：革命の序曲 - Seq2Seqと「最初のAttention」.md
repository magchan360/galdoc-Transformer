# 第3章：革命の序曲 - Seq2Seqと「最初のAttention」

  RNNのおかげで、AIは文章の「順番」を覚えられるようになった。じゃあ、次は何がしたくなると思う？
  そう、「翻訳」だよね！ 「日本語の文章」を「英語の文章」に変える、みたいな！

  この翻訳っていうマジでムズいタスクを攻略するために生まれたのが、「Seq2Seq（シーク・トゥ・シーク）」っていうモデル。そして、このSeq2Seqの中で、後の世界をマジで変えちゃう
  、ある「ひらめき」が生まれたんだ！

## 3.1 翻訳モデルのブレークスルー：Seq2Seq

  Seq2Seqは、一言でいうと「分業制の翻訳チーム」みたいな感じ。
  二人のプロが登場するんだ。

   1. エンコーダー君（文章をギュッと要約するプロ）
   2. デコーダーちゃん（要約から文章を復元するプロ）

  この二人がどうやって翻訳するか、見てみよっか。

  【例】「私は学生です」を翻訳する場合

   1. まず、日本語担当のエンコーダー君が「私」「は」「学生」「です」って順番に読む。
   2. 彼は、読んだ文章の「意味」とか「キモチ」をぜーんぶ、一個の小さなボールにギュギュ〜〜っと圧縮して要約するんだ。（このボールを専門用語でコンテキストベクトルって言うよ！）
   3. 次に、エンコーダー君は、そのボールを英語担当のデコーダーちゃんに「はい、これ！」ってパスする。
   4. デコーダーちゃんは、そのボールだけを見て、「ふむふむ、なるほどね。こういう意味ね」って理解して、「I」「am」「a」「student」って、英語の文章を一個ずつ作り上げていく。

  この「エンコーダーが文章を要約して、デコーダーがそれを元に新しい文章を作る」っていう流れが、Seq2Seqの基本！ これで、AIの翻訳能力はマジで上がったんだ。

  でも、弱点もあった。
  長い文章になると、エンコーダー君が作るボールに、全部の情報を詰め込むのがマジで大変だったの。「超長い手紙の内容を、たった一枚の付箋に要約して！」って言われてるようなもん
  。大事な情報が、どうしてもこぼれ落ちちゃうんだよね。

## 3.2 「どこに注目すべきか」を教えるAttention機構の登場

  「デコーダーちゃん、要約ボールだけじゃ情報足りなくて、マジ大変そう…」
  「そうだ！ デコーダーちゃんが翻訳するとき、元の文章をカンニングできるようにすればよくない！？」

  この天才的なひらめきこそが、「Attention（アテンション）」の始まりだったんだ！

  新しいルールが追加されたSeq2Seqは、こう動く。

  【例】「私は学生です」を翻訳する場合（Attention付き！）

   1. エンコーダー君が日本語を読むのは、前と一緒。
   2. デコーダーちゃんが、英語を作り始めるとき、ただボールを見るだけじゃない。元の日本語の文章が書かれた「カンニングペーパー」も、同時に見れるようになったんだ！
   3. デコーダーちゃんが、最初の単語「I」を作るとき、カンペの「私」のところをガン見する。
   4. 次に「am」を作るときも、まあ「私」とか「です」あたりをチラ見する。
   5. そして「a student」を作るときは、カンペの「学生です」のところを、また超ガン見する！

  わかる？
  翻訳する単語に合わせて、元の文章の「どこに注目（Attention）すべきか」を、AIが自分で判断できるようになったってワケ！

  ただの要約ボールだけを頼りにしてた時と比べて、翻訳の精度はマジで爆上がり！
  「この英語の単語は、元の日本語のこの部分から来てるんだな」って、対応関係がハッキリわかるようになったから、変な訳し間違いがめちゃくちゃ減ったんだ。

## 3.3 それでも残ったRNNの呪縛

  Attention、マジ最強じゃん！ これでAIは完成だ！
  …って、なりそうだけど、実はまだ、根本的な問題が残ってた。

  それは、エンコーダー君もデコーダーちゃんも、その正体はRNN（とかLSTM）だったってこと。

  カンニングっていう最強スキルは手に入れたけど、肝心の文章を読む・書くっていう作業は、相変わらず単語を一個ずつ、一個ずつ、マジメに順番に処理するしかなかったんだ。

  だから、計算がちょー遅い。
  それに、やっぱりちょー長い文章だと、カンペのどこを見るべきか、だんだん分かんなくなっちゃうこともあった。

  「Attentionっていう仕組み、マジでポテンシャルやばくない？」
  「 "順番に読む" って、本当に必要？いっそのこと、もう RNNやめない？」
  「Attentionさえあれば、全部うまくいくんじゃね？」

  そう、AI界の天才たちは、ついに気づいてしまった。
  自分たちを縛り付けていた「順番に読む」という呪縛。それを解き放つ鍵が、Attentionそのものにあるということに。

  そして、ついに、あの革命的な論文が生まれることになるんだ。
  さあ、次はいよいよ本章！ Transformerの登場だよ！
  