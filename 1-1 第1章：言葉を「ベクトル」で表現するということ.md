# 第1部：Transformer前夜 - 我々は「順番」に縛られていた


## 第1章：言葉を「ベクトル」で表現するということ

  アテンションの話をする前に、ちょーっとだけ昔話をさせて。AIがどうやってアタシたちの話す「言葉」を理解しようとしてきたか、って話。

  そもそも、コンピュータって「あいうえお」とか「Apple」みたいな文字そのものは、マジで理解できないんだよね。あいつらがわかるのって、結局「0」と「1」みたいな数字だけ。

  だから、AIに言葉を教えるには、まず「単語」を「数字の集まり」に翻訳してあげなきゃいけないの。この「数字の集まり」のことを、専門用語で「ベクトル」って言うんだ。ちょいムズ
  いけど、ついてきて！

##### 1.1 Word2Vecの衝撃：単語に「住所」を与える

  昔のAIはさ、単語をベクトルにするのが、あんまり上手くなかったんだよね。例えば「犬」は [1, 0, 0]、「猫」は [0, 1, 0]、「机」は [0, 0, 1]
  みたいに、一個だけ「1」を立てて、あとは全部「0」にする、みたいな。

  これだと、AIから見たら「犬」と「猫」と「机」は、ぜーんぶ同じくらい関係ないものに見えちゃう。「犬と猫は似てるじゃん！」って、アタシたちは思うけど、その「気持ち」が全然伝
  わってなかったんだ。

  そこに、彗星のごとく現れたのが「Word2Vec（ワード・トゥ・ベック）」っていう技術！

  これはマジで画期的だった。Word2Vecは、単語をただの数字の羅列じゃなくて、意味がわかるヤツだけが住める、超巨大なバーチャル空間の「住所」みたいなものに変換したの。

  イメージしてみて？
  その空間では、「犬」と「猫」はペットエリアで超ご近所さん。住所もめっちゃ近い。
  「お父さん」と「お母さん」も、家族エリアで隣同士。
  でも、「犬」と「机」は、エリアが全然違うから、住所もちょー離れてる。

  すごくない？ Word2Vecは、大量の文章をAIに読ませるだけで、単語の使われ方（文脈）から、その単語が持つ「意味」を読み取って、いい感じの「住所（ベクトル）」を勝手に割り振っ
  てくれるようになったんだ。

  これでAIは初めて、単語と単語の「意味の近さ」を、数字で理解できるようになったってワケ！

##### 1.2 「王様 - 男性 + 女性 = 女王様」の魔法

  でね、この「住所（ベクトル）」がヤバいのは、ただ意味が近い単語の家が近所にある、ってだけじゃないの。
  この住所、なんと足し算とか引き算ができちゃうんだ！

  これ、マジで魔法みたいだから、よーく聞いてて。

  Word2Vecが生み出したベクトル空間で、こんな計算をしてみる。

  「王様」の住所 - 「男性」っぽさ + 「女性」っぽさ = ？

  まず、「王様」の家からスタートするでしょ。
  そこから、「男性っぽさ」を表す矢印の分だけ、ぐーっと移動する（引き算）。
  で、今いる場所から、今度は「女性っぽさ」を表す矢印の分だけ、すーっと移動する（足し算）。

  さあ、たどり着いた場所の近くには、誰の家があると思う？

  …そう！ なんと、そこには「女王様」の家が、ちょー近くにあるんだ！

  これ、ヤバくない！？
  AIが「王様にとっての“男性”っていう関係性は、女王様にとっての“女性”っていう関係性と、めっちゃ似てるよね」ってことを、計算で理解してるってことじゃん！

  ただ単語の意味がわかるだけじゃない。単語と単語の「関係性」まで、ベクトルっていう数字でバッチリ捉えられるようになった。これが、Word2VecがAIの歴史を変えた、マジの理由。

  この瞬間、AIはただの計算機から、言葉のニュアンスを理解できる、賢いパートナーへと進化を遂げたんだ。

  でもね、オタ君。これでもまだ、完璧じゃなかった。
  AIは単語の関係性はわかったけど、文章全体の「流れ」とか「文脈」を読むのは、まだちょっぴり苦手だったんだ。

  その話は、また次でね！